<!DOCTYPE html>
<!-- TypeIt package -->
<script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="COAT: Discovery of the Hidden World with Large Language Models">
        <meta name="keywords" content="JailBreak, LLM, Security">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>COAT: Discovery of the Hidden World with Large Language Models</title>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-MK2R9XDD88"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() { dataLayer.push(arguments); }
            gtag('js', new Date());

            gtag('config', 'G-MK2R9XDD88');
        </script>
        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
        <link rel="stylesheet" href="./static/css/bulma.min.css">
        <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="./static/css/index.css">
        <link rel="icon" href="./static/images/causalcoat.webp">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>
        <script src="./static/js/bulma-carousel.min.js"></script>
        <script src="./static/js/bulma-slider.min.js"></script>
        <script src="./static/js/index.js"></script>
        <!-- Typing Effect JS -->
        <script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
        <script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/typeit/5.10.1/typeit.min.js"></script>
        <!-- / Typing Effect JS -->
        <style>
    .bigdiv {
      font-size: large;
      font-family: "Courier New";
      padding: 2rem;
    }
    p {
      padding: 2rem;
    }
        </style>
    </head>
    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">COAT: Discovery of the Hidden World with Large Language Models</h1>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <a href="https://chxliou.github.io/">Chenxi Liu</a>
                                    <sup>1*</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://lfhase.win">Yongqiang Chen</a>
                                    <sup>2,3*</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://tongliang-liu.github.io/">Tongliang Liu</a>
                                    <sup>4</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://mingming-gong.github.io/">Mingming Gong</a>
                                    <sup>5</sup>
                                    ,
                                </span>
                                <br>
                                <span class="author-block">
                                    <a href="https://www.cse.cuhk.edu.hk/~jcheng/">James Cheng</a>
                                    <sup>3</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://bhanml.github.io/">Bo Han</a>
                                    <sup>1</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>
                                    <sup>2,6</sup>
                                    ,
                                </span>
                            </div>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <sup>1</sup>Hong Kong Baptist University,
                                </span>
                                <span class="author-block">
                                    <sup>2</sup>MBZUAI,
                                </span>
                                <span class="author-block">
                                    <sup>3</sup>The Chinese University of Hong Kong
                                </span>
                                <br>
                                <span class="author-block">
                                    <sup>4</sup>The University of Sydney,
                                </span>
                                <span class="author-block">
                                    <sup>5</sup>The University of Melbourne,
                                </span>
                                <span class="author-block">
                                    <sup>6</sup>Carnegie Mellon University
                                </span>
                            </div>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block" style="font-size: 15px;">(
                                    <sup>*</sup>Equal Contribution)
                                </span>
                            </div>
                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <!-- PDF Link. -->
                                    <span class="link-block">
                                        <a href="https://arxiv.org/abs/2402.03941" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>Paper</span>
                                        </a>
                                    </span>
                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a href="https://causalcoat.github.io/" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
            <div class="content has-text-centered">
              <img src="./static/images/causalcoat.webp" style="width:200px;">
            </div>
            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Abstract</h2>
                            <div class="content has-text-justified">
                                <p>
                                    Science originates with discovering new causal knowledge from a combination of known facts and observations.
            Traditional causal discovery approaches mainly rely on high-quality measured variables, usually given by human
            experts, to find causal relations. However, the causal variables are usually unavailable in a wide range of real-world
            applications. The rise of large language models (LLMs) that are trained to learn rich knowledge from the massive
            observations of the world, provides a new opportunity to assist with discovering high-level hidden variables from the
            raw observational data. Therefore, we introduce COAT: Causal representatiOn AssistanT. COAT incorporates LLMs
            as an factor proposer that extracts the potential causal factors from unstructured data. Moreover, LLMs can also be
            instructed to provide additional information used to collect data values (e.g., annotation criteria) and to further
            parse
            the raw unstructured data into structured data. The annotated data will be fed to a causal learning module (e.g., the
            FCI algorithm) that provides both rigorous explanations of the data, as well as useful feedback to further improve the
            extraction of causal factors by LLMs. We verify the effectiveness of COAT in uncovering the underlying causal system
            with two case studies of review rating analysis and neuropathic diagnosis.
                                </p>
                            </div>
                        </div>
                    </div>
                    <!--/ Abstract. -->
                </div>
            </section>
            
            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">COAT Framework</h2>
                            <div class="content has-text-justified">
                                <!-- Add image -->
                                <div class="figure" style="align: left; text-align:center;">
                                    <img
                                        src="./static/paper_imgs/coat_illustration.jpg"
                                        alt="img description"
                                        width="800"
                                        height="600"
                                    >
                                    <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                        <b>Figure 1</b>. Illustration of the COAT framework.
                                    </p>
                                </div>
                                Inspired by real-world causal discovery applications, given a new task with
unstructured observational data, COAT aims to uncover the markov blanket with respect to a target variable:
                                <ul>
                                    <li>
                                        <b>(a) Factor Proposal.</b>
                                        COAT
                first adopts an LLM to read, comprehend, and relate the rich knowledge during pre-training to propose a series of
                candidate factors along with some meta-information such as annotation guidelines.
                                    </li>
                                    <li>
                                        <b>(b) Factor Annotation.</b>
                                        Based on the candidate factors, COAT
                then prompts another LLM to annotate or fetch the structured values of the unstructured data. With the annotated
                structured data.
                                    </li>
                                    <li>
                                        <b>(c1) Causal Discovery.</b>
                                        With the annotated
                structured data,the causal discovery algorithm is called to find causal relations among the factors
                                    </li>
                                    <li>
                                        <b>(c2) Feedback Construction.</b> By looking at samples where the target variable can not be well explained with the existing factors, LLM is expected to associate more related knowledge to uncover the desired causal factor.
                                    </li>
                                </ul>
                            </p>
                        </div>
                    </div>
                </div>
                <!--/ Abstract. -->
            </div>
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-full-width has-text-centered">
                        <h2 class="title is-3">Results on AppleGastronome Benchmark</h2>
                        <div class="content has-text-justified is-centered">
                            <p>
                                In this benchmark, gastronomes comment and rate apples according to their preference.
            Each apple has its own attributes, including size, smell, and taste (e.g. sweet or sour). 
            The target variable is the rating score.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/ExampleDataApple.png"
                                style="width:800px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Box 1</b>. Examples of AppleGastronome data, grouped by the value of scores.
                            </p>
                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b> Can LLMs be an effective factor proposer?</b>
                                It can be found that,
compared to other uses of LLMs, COAT obtain significant improvements regardless of which LLM is used. In contrast,
directly using LLMs to reason about the causal relations results in a high sensitivity to the capabilities of LLMs.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/table_1_AppleResults.png"
                                style="width:600px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content has-text-justified is-centered" style="color: gray; font-size: 10pt;">
                                <b>Table 1</b>
                                . Causal discovery results in AppleGastronome. MB, NMB and OT refer to the number of causal factors discovered
              in the underlying markov blanket, in the causal graph but not the markov blanket, and the other variables. Recall, precision,
              and F1 for factor proposal evaluate the discovered causal ancestors. Recall, precision, and F1 for relation extraction evaluate
              the recovery of the causal edges. The Data baseline refers to pairwise causal relation inference (Kiciman et al., 2023) based
              on the factors discovered by Data.
                            </p>
                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b> Can COAT reliably recover the causal relationships?</b>
                                Compared to the ground truth results, directly adopting LLMs
to reason about the causal relations can easily elicit lots of false positive causal relations. In contrast, the relations recovered
by COAT have a high precision as well as the recall. The directed edge between “taste” and “juiciness” can not be recovered
by COAT is because of the limitations of FCI.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/Example_Apple.png"
                                style="width:800px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 2</b>. The discovered causal graphs in AppleGastronome.
                            </p>
                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b>Can LLMs be an effective factor annotator?</b>
                                Moreover, since LLMs are also used to annotate the data according
to the proposed annotation guidelines, we analyze the capabilities of LLMs in terms of annotation accuracy. It can be found that both LLMs are generally good at annotating objective attributes. When it comes to
              the human subjective preferences, the performance of GPT-3.5 will decrease while being relatively high.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/Annotation_Accu.png"
                                style="width:500px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content has-text-justified is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 3</b>.  Annotation accuracies of GPT-4 and GPT-3.5 for apple attributes and preference matchness in AppleGastronome
                            </p>
                        </div>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b>Will LLMs introduce additional confounders in annotating factors?</b>
                                In addition, since the annotated results by
LLMs will involve additional noises, or even additional confounders, we also conduct independence tests among the annotation noises and the features.  It can be found that, with highly capable LLMs, e.g., GPT-4-Turbo, the dependencies can be controlled under an acceptable level.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/indp_test_apple.png"
                                style="width:300px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content has-text-justified is-centered" style="color: gray; font-size: 10pt;">
                                <b>Table 2</b>
                                . Independence tests of the annotation noises with annotated features and other noises in AppleGastronome.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-full-width has-text-centered">
                        <h2 class="title is-3">Results on Neuropathic Benchmark</h2>
                        <div class="content has-text-justified is-centered">
                            <p>
                                In the original dataset, there are three levels of causal variables, including the symptom-level, radiculopathy-level and
the pathophysiology-level. In this project, we mainly consider the target variable of
                                <b>right shoulder impingement</b>
                                .
When generating the clinical diagnosis notes as x using GPT-4, we will
                                <b>
                                    avoid any mentioning of variables other than
symptoms
                                </b>
                                .
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/ExampleDataNeuro.png"
                                style="width:800px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Box 2</b>. Examples of Neuropathic data, grouped by the presence of one certain symptom.
                            </p>
                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b> Factor proposal.</b>
                                Similarly, we can find that
              COAT consistently outperforms all of the baselines regardless of which LLMs are incorporated. In particular, COAT
              can boost the weakest backbone LLaMA2-7b to be better than any other LLMs.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/table_2_NeuroResults.png"
                                style="width:400px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content has-text-justified is-centered" style="color: gray; font-size: 10pt;">
                                <b>Table 3</b>
                                . Causal discovery results in Neuropathic. PA, AN, and OT refer to the parents, ancestors, and others, respectively.
              Accuracy and F1 measure the recovery of the causal ancestors.
                            </p>
                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <p>
                                <b> Causal relation recovery.</b>
                                Due to the faithfulness issue of the original dataset (Tu et al., 2019), we mainly conduct a qualitative comparison between the ground truth that is faithful to the data, against the
              baselines and COAT.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/Example_Neuro.png"
                                style="width:800px;"
                                class="result-image"
                                alt="Interpolation end reference image."
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 4</b>. The discovered causal graphs in Neuropathic.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
                <h2 class="title">Contact</h2>
                <p>
                    Welcome to check our paper for more details of the research work. If there is any question, please feel free to contact us.
                </p>
                <p>
                    If you find our paper and repo useful, please consider to cite:
                </p>
                <pre>
                    <code>
    @article{causalcoat2024,
      title={COAT: Discovery of the Hidden World with Large Language Models}, 
      author={Chenxi Liu and Yongqiang Chen and Tongliang Liu and Mingming Gong and James Cheng and Bo Han and Kun Zhang},
      year={2024},
      journal = {arXiv preprint},
      volume = {arXiv:2402.03941}
    }
                    </code>
                </pre>
                <br>
            </div>
        </section>
        <footer class="footer">
            <div class="container">
                <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content">
                            <p>
                                Thanks for the source template from
                                <a href="https://github.com/nerfies/nerfies.github.io">here</a>
                                .
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
